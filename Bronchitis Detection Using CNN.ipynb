{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8458bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import All Required Librarys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "import cv2\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1708b55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Flatten,Dense\n",
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97b5da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGESHAPE = [224, 224, 3] \n",
    "training_data = r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\test'\n",
    "testing_data = r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52585dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = VGG16(input_shape=IMAGESHAPE, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "694cf6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_layer in vgg_model.layers:\n",
    "    each_layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9006e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = glob(r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\train\\*') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d775eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_layer = Flatten()(vgg_model.output)\n",
    "prediction = Dense(len(classes), activation='softmax')(flatten_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b79ead25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = Model(inputs=vgg_model.input, outputs=prediction) \n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eee5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile( \n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a2ee98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, \n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "testing_datagen = ImageDataGenerator(rescale =1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64cfcec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5232 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\train', \n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 4,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f69b31d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = testing_datagen.flow_from_directory(r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\test',\n",
    "                                               target_size = (224, 224),\n",
    "                                               batch_size = 4,\n",
    "                                               class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37e9b676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1308/1308 [==============================] - 1419s 1s/step - loss: 0.2711 - accuracy: 0.9192 - val_loss: 0.3468 - val_accuracy: 0.9199\n",
      "Epoch 2/5\n",
      "1308/1308 [==============================] - 1618s 1s/step - loss: 0.2660 - accuracy: 0.9442 - val_loss: 0.5987 - val_accuracy: 0.9151\n",
      "Epoch 3/5\n",
      "1308/1308 [==============================] - 1399s 1s/step - loss: 0.2203 - accuracy: 0.9520 - val_loss: 0.4862 - val_accuracy: 0.9279\n",
      "Epoch 4/5\n",
      "1308/1308 [==============================] - 1714s 1s/step - loss: 0.2164 - accuracy: 0.9585 - val_loss: 0.5604 - val_accuracy: 0.9167\n",
      "Epoch 5/5\n",
      "1308/1308 [==============================] - 1578s 1s/step - loss: 0.2038 - accuracy: 0.9568 - val_loss: 1.0951 - val_accuracy: 0.8846\n"
     ]
    }
   ],
   "source": [
    "fitted_model = final_model.fit( \n",
    " training_set,\n",
    " validation_data=test_set,\n",
    " epochs=5,\n",
    " steps_per_epoch=len(training_set),\n",
    " validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea6befe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save Final model\n",
    "final_model.save(r'C:\\Users\\Asus\\our_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8669de36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec52b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee9d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d73ebcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 716ms/step\n",
      "Person is affected with Pneumonia.\n",
      "Predictions: [[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from keras_preprocessing import image\n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "model=load_model(r'C:\\Users\\Asus\\our_model.h5') #Loading our model\n",
    "img=image.load_img(r\"C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\train\\PNEUMONIA\\person9_bacteria_38.jpeg\",target_size=(224,224))\n",
    "imagee=image.img_to_array(img) #Converting the X-Ray into pixels\n",
    "imagee=np.expand_dims(imagee, axis=0)\n",
    "img_data=preprocess_input(imagee)\n",
    "prediction=model.predict(img_data)\n",
    "if prediction[0][0]>prediction[0][1]:  #Printing the prediction of model.\n",
    "    print('Person is safe.')\n",
    "else:\n",
    "    print('Person is affected with Pneumonia.')\n",
    "print(f'Predictions: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266afcfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0716b2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91bb335",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f3e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 25089     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,739,777\n",
      "Trainable params: 25,089\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 5232 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_15304/848059739.py:42: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  fitted_model = final_model.fit_generator(\n"
     ]
    }
   ],
   "source": [
    "# full code \n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten,Dense\n",
    "from keras.applications.vgg16 import VGG16  #Import all the necessary modules\n",
    "import matplotlib.pyplot as plot\n",
    "from glob import glob\n",
    "  \n",
    "IMAGESHAPE = [224, 224, 3] #Provide image size as 224 x 224 this is a fixed-size for VGG16 architecture\n",
    "vgg_model = VGG16(input_shape=IMAGESHAPE, weights='imagenet', include_top=False)\n",
    "#3 signifies that we are working with RGB type of images.\n",
    "training_data = r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\test'\n",
    "testing_data = r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\train' #Give our training and testing path\n",
    "  \n",
    "for each_layer in vgg_model.layers:\n",
    "    each_layer.trainable = False #Set the trainable as False, So that all the layers would not be trained.\n",
    "classes = glob(r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\train') #Finding how many classes present in our train dataset.\n",
    "flatten_layer = Flatten()(vgg_model.output)\n",
    "prediction = Dense(len(classes), activation='softmax')(flatten_layer)\n",
    "final_model = Model(inputs=vgg_model.input, outputs=prediction) #Combine the VGG output and prediction , this all together will create a model.\n",
    "final_model.summary() #Displaying the summary\n",
    "final_model.compile( #Compiling our model using adam optimizer and optimization metric as accuracy.\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255., #importing our dataset to keras using ImageDataGenerator in keras.\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "testing_datagen = ImageDataGenerator(rescale =1/255.)\n",
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\test', #inserting the images.\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 224,\n",
    "                                                 class_mode = 'binary')\n",
    "test_set = testing_datagen.flow_from_directory(r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\train',\n",
    "                                               target_size = (224, 224),\n",
    "                                               batch_size = 224,\n",
    "                                               class_mode = 'binary')\n",
    "#fitted model generator\n",
    "fitted_model = final_model.fit_generator(\n",
    "training_set,\n",
    "validation_data=test_set,\n",
    "epochs=10,\n",
    "steps_per_epoch=len(training_set),\n",
    "validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "\n",
    "final_model.save(r'C:\\Users\\Asus\\our_model.h5') #Saving the model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a2ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Flatten,Dense\n",
    "from keras.applications.vgg16 import VGG16  #Import all the necessary modules\n",
    "import matplotlib.pyplot as plot\n",
    "from glob import glob\n",
    "  \n",
    "IMAGESHAPE = [224, 224, 3] #Provide image size as 224 x 224 this is a fixed-size for VGG16 architecture\n",
    "vgg_model = VGG16(input_shape=IMAGESHAPE, weights='imagenet', include_top=False)\n",
    "#3 signifies that we are working with RGB type of images.\n",
    "training_data = r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\test'\n",
    "testing_data = r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\train' #Give our training and testing path\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_layer in vgg_model.layers:\n",
    "    each_layer.trainable = False #Set the trainable as False, So that all the layers would not be trained.\n",
    "classes = glob(r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\train') #Finding how many classes present in our train dataset.\n",
    "flatten_layer = Flatten()(vgg_model.output)\n",
    "prediction = Dense(len(classes), activation='softmax')(flatten_layer)\n",
    "final_model = Model(inputs=vgg_model.input, outputs=prediction) #Combine the VGG output and prediction , this all together will create a model.\n",
    "final_model.summary() #Displaying the summary\n",
    "final_model.compile( #Compiling our model using adam optimizer and optimization metric as accuracy.\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, #importing our dataset to keras using ImageDataGenerator in keras.\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "testing_datagen = ImageDataGenerator(rescale =1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_set = train_datagen.flow_from_directory(r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\test', #inserting the images.\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 4,\n",
    "                                                 class_mode = 'categorical')\n",
    "test_set = testing_datagen.flow_from_directory(r'C:\\Users\\Asus\\Desktop\\Bronchitis Project\\Other Datasets\\chest_xray\\train',\n",
    "                                               target_size = (224, 224),\n",
    "                                               batch_size = 4,\n",
    "                                               class_mode = 'categorical')\n",
    " #Fitting the model.\n",
    "fitted_model = final_model.fit(training_set,validation_data=test_set,epochs=10,steps_per_epoch=len(training_set),validation_steps=len(test_set)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca50fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1493341",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check where the train model is save \n",
    "\n",
    "import os;\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae1c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing code\n",
    "\n",
    "from keras_preprocessing import image\n",
    "from keras.models import load_model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "model=load_model(r'C:\\Users\\Asus\\our_model.h5') #Loading our model\n",
    "img=image.load_img(r\"C:\\Users\\Asus\\Desktop\\NORMAL-1110860-0001.jpeg\",target_size=(224,224))\n",
    "imagee=image.img_to_array(img) #Converting the X-Ray into pixels\n",
    "imagee=np.expand_dims(imagee, axis=0)\n",
    "img_data=preprocess_input(imagee)\n",
    "prediction=model.predict(img_data)\n",
    "if prediction[0][0]>prediction[0][1]:  #Printing the prediction of model.\n",
    "    print('Person is safe.')\n",
    "else:\n",
    "    print('Person is affected with Pneumonia.')\n",
    "print(f'Predictions: {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7333f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbffb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7863f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae413cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee293f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall -y torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df57e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf20dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow-gpu==1.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61990573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc34644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement keras-gpu (from versions: none)\n",
      "ERROR: No matching distribution found for keras-gpu\n"
     ]
    }
   ],
   "source": [
    "pip install keras-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46b6a03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "Collecting python_version>\"3.7\"\n",
      "  Downloading python_version-0.0.2-py2.py3-none-any.whl (3.4 kB)\n",
      "Building wheels for collected packages: tensorflow-gpu\n",
      "  Building wheel for tensorflow-gpu (setup.py): started\n",
      "  Building wheel for tensorflow-gpu (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for tensorflow-gpu\n",
      "Failed to build tensorflow-gpu\n",
      "Installing collected packages: python-version, tensorflow-gpu\n",
      "    Running setup.py install for tensorflow-gpu: started\n",
      "    Running setup.py install for tensorflow-gpu: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'D:\\New folder\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Asus\\\\AppData\\\\Local\\\\Temp\\\\pip-install-fisoy45q\\\\tensorflow-gpu_2cb7b387464547e4898590dbfd76e624\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Asus\\\\AppData\\\\Local\\\\Temp\\\\pip-install-fisoy45q\\\\tensorflow-gpu_2cb7b387464547e4898590dbfd76e624\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d 'C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-wheel-gwz6yw38'\n",
      "       cwd: C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-install-fisoy45q\\tensorflow-gpu_2cb7b387464547e4898590dbfd76e624\\\n",
      "  Complete output (17 lines):\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-install-fisoy45q\\tensorflow-gpu_2cb7b387464547e4898590dbfd76e624\\setup.py\", line 37, in <module>\n",
      "      raise Exception(TF_REMOVAL_WARNING)\n",
      "  Exception:\n",
      "  \n",
      "  =========================================================\n",
      "  The \"tensorflow-gpu\" package has been removed!\n",
      "  \n",
      "  Please install \"tensorflow\" instead.\n",
      "  \n",
      "  Other than the name, the two packages have been identical\n",
      "  since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "  information, see: pypi.org/project/tensorflow-gpu\n",
      "  =========================================================\n",
      "  \n",
      "  \n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for tensorflow-gpu\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'D:\\New folder\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Asus\\\\AppData\\\\Local\\\\Temp\\\\pip-install-fisoy45q\\\\tensorflow-gpu_2cb7b387464547e4898590dbfd76e624\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Asus\\\\AppData\\\\Local\\\\Temp\\\\pip-install-fisoy45q\\\\tensorflow-gpu_2cb7b387464547e4898590dbfd76e624\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-record-jef63jf6\\install-record.txt' --single-version-externally-managed --compile --install-headers 'D:\\New folder\\Include\\tensorflow-gpu'\n",
      "         cwd: C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-install-fisoy45q\\tensorflow-gpu_2cb7b387464547e4898590dbfd76e624\\\n",
      "    Complete output (17 lines):\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-install-fisoy45q\\tensorflow-gpu_2cb7b387464547e4898590dbfd76e624\\setup.py\", line 37, in <module>\n",
      "        raise Exception(TF_REMOVAL_WARNING)\n",
      "    Exception:\n",
      "    \n",
      "    =========================================================\n",
      "    The \"tensorflow-gpu\" package has been removed!\n",
      "    \n",
      "    Please install \"tensorflow\" instead.\n",
      "    \n",
      "    Other than the name, the two packages have been identical\n",
      "    since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "    information, see: pypi.org/project/tensorflow-gpu\n",
      "    =========================================================\n",
      "    \n",
      "    \n",
      "    ----------------------------------------\n",
      "ERROR: Command errored out with exit status 1: 'D:\\New folder\\python.exe' -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Asus\\\\AppData\\\\Local\\\\Temp\\\\pip-install-fisoy45q\\\\tensorflow-gpu_2cb7b387464547e4898590dbfd76e624\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Asus\\\\AppData\\\\Local\\\\Temp\\\\pip-install-fisoy45q\\\\tensorflow-gpu_2cb7b387464547e4898590dbfd76e624\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record 'C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-record-jef63jf6\\install-record.txt' --single-version-externally-managed --compile --install-headers 'D:\\New folder\\Include\\tensorflow-gpu' Check the logs for full command output.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b75c6994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-models\n",
      "  Downloading keras_models-0.0.7-py3-none-any.whl (18 kB)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.5.2-cp39-cp39-win_amd64.whl (12.2 MB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\n",
      "    data = self._fp.read(amt) if not fp_closed else b\"\"\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\n",
      "    data = self.__fp.read(amt)\n",
      "  File \"D:\\New folder\\lib\\http\\client.py\", line 462, in read\n",
      "    n = self.readinto(b)\n",
      "  File \"D:\\New folder\\lib\\http\\client.py\", line 506, in readinto\n",
      "    n = self.fp.readinto(b)\n",
      "  File \"D:\\New folder\\lib\\socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "  File \"D:\\New folder\\lib\\ssl.py\", line 1241, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "  File \"D:\\New folder\\lib\\ssl.py\", line 1099, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "socket.timeout: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 173, in _main\n",
      "    status = self.run(options, args)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 203, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 315, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 94, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 472, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 366, in resolve\n",
      "    failure_causes = self._attempt_to_pin_criterion(name)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 212, in _attempt_to_pin_criterion\n",
      "    criteria = self._get_updated_criteria(candidate)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 203, in _get_updated_criteria\n",
      "    self._add_to_criteria(criteria, requirement, parent=candidate)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 172, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 151, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 140, in __bool__\n",
      "    return any(self)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 128, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 32, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 204, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 295, in __init__\n",
      "    super().__init__(\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 227, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 305, in _prepare_distribution\n",
      "    return self._factory.preparer.prepare_linked_requirement(\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 508, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 550, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 239, in unpack_url\n",
      "    file = get_http_url(\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 102, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 145, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 144, in iter\n",
      "    for x in it:\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\n",
      "    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\n",
      "  File \"D:\\New folder\\lib\\contextlib.py\", line 137, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"D:\\New folder\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aca967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
